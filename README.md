# team-crux-p1

Distributed document classification using Apache Spark.

This project seeks to build a model capable of classifying news stories into one of the following four categories:
* Corporate/Industrial (CCAT)
* Economics (ECAT)
* Government/Social (GCAT)
* Markets (MCAT)

This repository contains python scripts to build classification models and serialize their output.  The following models
are available:
* Naive Bayes
* Others?  <!--- TODO -->

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing 
purposes.

### Prerequisites

TODO: What things you need to install the software and how to install them

### Installing

TODO: A step by step series of examples that tell you have to get a development env running

### Running experiments

TODO: example of how to run one of the scripts

## Running the tests

TODO: Fill this section if we add unit tests

## Deployment

TODO: notes on how to run this on a production cluster

## Built With

* [Apache Spark](https://spark.apache.org/) - Distributed computing engine
* [Python 3.6](https://www.python.org/)

## Contributing

There are no specific guidelines for contributing as of yet.  Feel free to send a pull request if you have
some improvement.

## Versioning

We use the [GitFlow](https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow) 
workflow to organize releases and development of new features.

## Authors

See the [contributors](https://github.com/dsp-uga/team-crux-p1/contributors.md) file for details

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details

## Acknowledgments

* This project was completed as a part of the Data Science Practicum 2018 course at the University of Georgia
* [Dr. Shannon Quinn](https://github.com/magsol)
 is responsible for the problem formulation and initial guidance towards solution methods


